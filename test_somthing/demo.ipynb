{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "Fetching page 2...\n",
      "Fetching page 3...\n",
      "Fetching page 4...\n",
      "Fetching page 5...\n",
      "Fetching page 6...\n",
      "Fetching page 7...\n",
      "Fetching page 8...\n",
      "Fetching page 9...\n",
      "Total reviews fetched: 90\n",
      "Total unique reviews: 87\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def get_reviews(product_id, page=1):\n",
    "    url = f\"https://tiki.vn/api/v2/reviews?product_id={product_id}&limit=10&page={page}&include=comments\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        reviews = data.get('data', [])\n",
    "        return reviews\n",
    "    else:\n",
    "        print(f\"Failed to fetch reviews: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def save_reviews_to_file(reviews, filename=\"reviews.json\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(reviews, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def remove_duplicates(reviews):\n",
    "    # Dùng set để loại bỏ trùng lặp dựa trên nội dung bình luận\n",
    "    seen = set()\n",
    "    unique_reviews = []\n",
    "    for review in reviews:\n",
    "        content = review.get('content', '').strip()\n",
    "        if content not in seen:\n",
    "            seen.add(content)\n",
    "            unique_reviews.append(review)\n",
    "    return unique_reviews\n",
    "\n",
    "\n",
    "def main():\n",
    "    product_id = 3480333  # ID của sản phẩm từ URL\n",
    "    all_reviews = []\n",
    "    for page in range(1, 10):  # Crawl 9 trang\n",
    "        print(f\"Fetching page {page}...\")\n",
    "        reviews = get_reviews(product_id, page)\n",
    "        if not reviews:\n",
    "            break\n",
    "        all_reviews.extend(reviews)\n",
    "    \n",
    "    print(f\"Total reviews fetched: {len(all_reviews)}\")\n",
    "\n",
    "    # Loại bỏ bình luận trùng lặp\n",
    "    unique_reviews = remove_duplicates(all_reviews)\n",
    "    print(f\"Total unique reviews: {len(unique_reviews)}\")\n",
    "\n",
    "    # Lưu các bình luận đã loại bỏ trùng lặp\n",
    "    save_reviews_to_file(unique_reviews)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 86 reviews and saved to reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_reviews_to_csv(json_file, csv_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    filtered_reviews = []\n",
    "    \n",
    "    # Lọc bình luận và nhãn\n",
    "    for review in data:\n",
    "        content = review.get(\"content\", \"\").strip()\n",
    "        \n",
    "        if content:\n",
    "            filtered_reviews.append({\"content\": content})\n",
    "    \n",
    "    # Ghi dữ liệu vào file CSV\n",
    "    with open(csv_file, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"content\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(filtered_reviews)\n",
    "    \n",
    "    print(f\"Extracted {len(filtered_reviews)} reviews and saved to {csv_file}\")\n",
    "\n",
    "# Sử dụng\n",
    "input_file = \"reviews.json\"  # Tệp JSON đầu vào\n",
    "output_csv = \"reviews.csv\"  # Tệp CSV đầu ra\n",
    "extract_reviews_to_csv(input_file, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content\n",
      "0  Shop mới vừa chạy chương trình tặng ly nhựa 7 ...\n",
      "1  Đã nhận hàng như quảng cáo, hàng đẹp, chất lượ...\n",
      "2  Tiki là một thế giới rất diệu kỳ dành cho nhữn...\n",
      "3  Hàng chưa sử dụng nên chưa biết thế nào. Nhưng...\n",
      "4  Ấm đẹp, lòng ấm inox liền khối, sôi nhanh max ...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content\n",
      "0  shop chạy chương trình tặng ly nhựa 7 tây 8 tâ...\n",
      "1  hàng quảng cáo hàng đẹp chất thời gian sử dụng...\n",
      "2  tiki giới diệu kỳ đam mê mua sắm mua giá rẻ fr...\n",
      "3  hàng sử dụng giao hàng văn hóa tan tầm đt chạy...\n",
      "4  ấm đẹp ấm inox liền khối sôi max ấm 4 phút nhi...\n"
     ]
    }
   ],
   "source": [
    "# Đọc tệp stopword_vietnamese.txt và tạo danh sách từ dừng\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stopwords = file.readlines()\n",
    "    stopwords = [word.strip() for word in stopwords]  # Loại bỏ khoảng trắng thừa\n",
    "    return stopwords\n",
    "\n",
    "# Tải stopwords\n",
    "stop_words = load_stopwords(\"stopwords_vietnamese.txt\")\n",
    "\n",
    "# Loại bỏ từ dừng\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "# Chuấn hóa dữ liệu\n",
    "def standardize_data(row):\n",
    "    # Convert to lowercase\n",
    "    row = row.lower()\n",
    "    \n",
    "    # Remove stopwords (if you have a list of stopwords, you can use it here)\n",
    "    row = row.replace(\",\", \" \").replace(\".\", \" \") \\\n",
    "        .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
    "        .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
    "        .replace('\"', \" \").replace(\"'\", \" \") \\\n",
    "        .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
    "        .replace(\"-\", \" \").replace(\"?\", \" \") \\\n",
    "        .replace(\"(\", \" \").replace(\")\", \" \")\n",
    "\n",
    "    row = row.strip()\n",
    "    return row\n",
    "\n",
    "df['content'] = df['content'].apply(standardize_data).apply(remove_stopwords)\n",
    "print(df.head())\n",
    "\n",
    "# Lưu dữ liệu đã xử lý vào file mới\n",
    "output_file = \"processed_reviews.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
